{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dgl-tutorials.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPXc08owJaQRTC3gr6i+00s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhld99/dgl-tutorials/blob/main/dgl_tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c23nyBW1HwrT"
      },
      "source": [
        "# Overall Results:\n",
        "\n",
        "\n",
        "1.   `Node Classification` with DGL\n",
        "\n",
        "  - Cora Dataset\n",
        "      - NumNodes: 2708\n",
        "      - NumEdges: 10556\n",
        "      - NumFeats: 1433\n",
        "      - NumClasses: 7\n",
        "      - NumTrainingSamples: 140\n",
        "      - NumValidationSamples: 500\n",
        "      - NumTestSamples: 1000\n",
        "      - Number of categories: 7\n",
        "  - 100 epochs\n",
        "  - Accuracy: 0.768\n",
        "  - CPU time: 1.2 s\n",
        "  - GPU time: 488 ms \n",
        "\n",
        "2.   `Link Prediction` using Graph Neural Networks\n",
        "\n",
        "  - Cora Dataset\n",
        "      - Train/Test = 90%/10% for positive examples\n",
        "      - Randomly sample the same amount from abitrary edges for negative examples\n",
        "  - 100 epochs\n",
        "  - Optimizer: Adam `(lr=0.01)`\n",
        "  - Accuracy: `(AUC)` 0.8632950742346308\n",
        "  - Time: 4.39 s\n",
        "\n",
        "3.   Training a GNN for `Graph Classification`\n",
        "\n",
        "  - Small dataset from the paper [How Powerful Are Graph Neural Networks](https://arxiv.org/abs/1810.00826).\n",
        "      - Node feature dimensionality: 3\n",
        "      - Number of graph categories: 2 \n",
        "  - 20 epochs\n",
        "  - Optimizer: Adam `(lr=0.01)`\n",
        "  - Accuracy: 0.21524663677130046\n",
        "  - Time: 9.85 s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3UynS_r1aa1",
        "outputId": "8582049b-4f8d-4de7-cd30-ffdce4c26b36"
      },
      "source": [
        "!pip3 install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/c9/b413a24f759641bc27ef98c144b590023c8038dfb8a3f09e713e9dff12c1/ipython_autotime-0.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.0.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (54.1.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1\n",
            "time: 585 µs (started: 2021-03-19 18:54:08 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtD_JrfqkoSU"
      },
      "source": [
        "# Node Classification with DGL\n",
        "\n",
        "\n",
        "\n",
        "- Load a DGL-provided dataset.\n",
        "\n",
        "- Build a GNN model with DGL-provided neural network modules.\n",
        "\n",
        "- Train and evaluate a GNN model for node classification on either CPU or GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRimHtdPkHYq",
        "outputId": "5024bae6-5198-4a92-e1f2-e29f23e2eff0"
      },
      "source": [
        "!pip3 install dgl-cu101"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl-cu101\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/f3/a1b614ca8e12e92b53f4673b12a4968da2b94c357df8597f41b1d568755b/dgl_cu101-0.6.0.post1-cp37-cp37m-manylinux1_x86_64.whl (36.0MB)\n",
            "\u001b[K     |████████████████████████████████| 36.0MB 94kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (1.19.5)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (2.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (2.10)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.1->dgl-cu101) (4.4.2)\n",
            "Installing collected packages: dgl-cu101\n",
            "Successfully installed dgl-cu101-0.6.0.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTv-NVdqjpLa",
        "outputId": "c67bfef9-d581-430e-a793-6f67a4d7fd34"
      },
      "source": [
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijlM9h9tkw0a"
      },
      "source": [
        "## Loading Cora Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnGVzHfbjz53",
        "outputId": "7c68c27f-3558-42e3-d41b-658c772c949b"
      },
      "source": [
        "import dgl.data\n",
        "\n",
        "dataset = dgl.data.CoraGraphDataset()\n",
        "print('Number of categories:', dataset.num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n",
            "Extracting file to /root/.dgl/cora_v2\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n",
            "Number of categories: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ7xB9OYkbpx"
      },
      "source": [
        "g = dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUGHWtAqkfvq",
        "outputId": "993a75fd-56f6-4f56-ba31-fe11dca7fbc4"
      },
      "source": [
        "print('Node features')\n",
        "print(g.ndata)\n",
        "print('Edge features')\n",
        "print(g.edata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Node features\n",
            "{'train_mask': tensor([ True,  True,  True,  ..., False, False, False]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True]), 'label': tensor([3, 4, 4,  ..., 3, 3, 3]), 'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
            "Edge features\n",
            "{}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9FNFcaGk20w"
      },
      "source": [
        "## Defining a Graph Convolutional Network (GCN)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbARyPCOkibS"
      },
      "source": [
        "from dgl.nn import GraphConv\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n",
        "\n",
        "# Create the model with given dimensions\n",
        "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvrKf-NLk7QQ"
      },
      "source": [
        "## Training the GCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k0KSsBE2afC",
        "outputId": "ae8dff2d-af19-4a51-ac71-f0299c535533"
      },
      "source": [
        "g = g.to('cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.72 ms (started: 2021-03-19 18:57:53 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnn_Rhd32Qo3",
        "outputId": "523756d3-a41f-4683-a593-f654934c5bcd"
      },
      "source": [
        "def train(g, model):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    best_val_acc = 0\n",
        "    best_test_acc = 0\n",
        "\n",
        "    features = g.ndata['feat']\n",
        "    labels = g.ndata['label']\n",
        "    train_mask = g.ndata['train_mask']\n",
        "    val_mask = g.ndata['val_mask']\n",
        "    test_mask = g.ndata['test_mask']\n",
        "    for e in range(100):\n",
        "        # Forward\n",
        "        logits = model(g, features)\n",
        "\n",
        "        # Compute prediction\n",
        "        pred = logits.argmax(1)\n",
        "\n",
        "        # Compute loss\n",
        "        # Note that you should only compute the losses of the nodes in the training set.\n",
        "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
        "\n",
        "        # Compute accuracy on training/validation/test\n",
        "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "\n",
        "        # Save the best validation accuracy and the corresponding test accuracy.\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
        "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 20.7 ms (started: 2021-03-19 18:57:01 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C68TDBYjklK2",
        "outputId": "5f7a5c56-35d6-4dff-acda-da642231d8bf"
      },
      "source": [
        "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
        "train(g, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In epoch 0, loss: 1.946, val acc: 0.104 (best 0.104), test acc: 0.096 (best 0.096)\n",
            "In epoch 5, loss: 1.901, val acc: 0.416 (best 0.446), test acc: 0.410 (best 0.456)\n",
            "In epoch 10, loss: 1.826, val acc: 0.462 (best 0.462), test acc: 0.458 (best 0.458)\n",
            "In epoch 15, loss: 1.728, val acc: 0.590 (best 0.590), test acc: 0.629 (best 0.629)\n",
            "In epoch 20, loss: 1.608, val acc: 0.634 (best 0.634), test acc: 0.665 (best 0.665)\n",
            "In epoch 25, loss: 1.468, val acc: 0.672 (best 0.672), test acc: 0.698 (best 0.690)\n",
            "In epoch 30, loss: 1.312, val acc: 0.708 (best 0.708), test acc: 0.731 (best 0.731)\n",
            "In epoch 35, loss: 1.147, val acc: 0.730 (best 0.730), test acc: 0.746 (best 0.742)\n",
            "In epoch 40, loss: 0.980, val acc: 0.750 (best 0.750), test acc: 0.754 (best 0.754)\n",
            "In epoch 45, loss: 0.819, val acc: 0.752 (best 0.752), test acc: 0.756 (best 0.758)\n",
            "In epoch 50, loss: 0.672, val acc: 0.766 (best 0.766), test acc: 0.760 (best 0.759)\n",
            "In epoch 55, loss: 0.545, val acc: 0.766 (best 0.766), test acc: 0.761 (best 0.759)\n",
            "In epoch 60, loss: 0.440, val acc: 0.784 (best 0.784), test acc: 0.767 (best 0.767)\n",
            "In epoch 65, loss: 0.354, val acc: 0.788 (best 0.788), test acc: 0.770 (best 0.768)\n",
            "In epoch 70, loss: 0.287, val acc: 0.784 (best 0.788), test acc: 0.773 (best 0.768)\n",
            "In epoch 75, loss: 0.234, val acc: 0.786 (best 0.788), test acc: 0.771 (best 0.768)\n",
            "In epoch 80, loss: 0.193, val acc: 0.784 (best 0.788), test acc: 0.773 (best 0.768)\n",
            "In epoch 85, loss: 0.160, val acc: 0.786 (best 0.788), test acc: 0.773 (best 0.768)\n",
            "In epoch 90, loss: 0.135, val acc: 0.782 (best 0.788), test acc: 0.772 (best 0.768)\n",
            "In epoch 95, loss: 0.114, val acc: 0.780 (best 0.788), test acc: 0.774 (best 0.768)\n",
            "time: 1.2 s (started: 2021-03-19 18:58:00 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSJNWU5mvsaq",
        "outputId": "4863f520-bd09-4247-b1ec-f15cea6dc530"
      },
      "source": [
        "# example of evaluating new node's classification\n",
        "def evaluate(model, graph, features, labels, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(graph, features)\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        _, indices = torch.max(logits, dim=1)\n",
        "        correct = torch.sum(indices == labels)\n",
        "        return correct.item() * 1.0 / len(labels)\n",
        "\n",
        "evaluate(model, g, g.ndata['feat'], g.ndata['label'], g.ndata['test_mask'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.749"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbrrQpIzlBI0"
      },
      "source": [
        "## Training on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCAuaEiP2KlE",
        "outputId": "76edc5f2-0fbe-44c6-c717-dfc11280ce0e"
      },
      "source": [
        "g = g.to('cuda')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.15 ms (started: 2021-03-19 18:59:51 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XgohlW6k9KO",
        "outputId": "754e98dc-828b-4a4a-b3f2-205f7ae2b773"
      },
      "source": [
        "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes).to('cuda')\n",
        "train(g, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In epoch 0, loss: 1.946, val acc: 0.224 (best 0.224), test acc: 0.249 (best 0.249)\n",
            "In epoch 5, loss: 1.897, val acc: 0.558 (best 0.558), test acc: 0.596 (best 0.596)\n",
            "In epoch 10, loss: 1.820, val acc: 0.696 (best 0.696), test acc: 0.696 (best 0.696)\n",
            "In epoch 15, loss: 1.718, val acc: 0.696 (best 0.696), test acc: 0.697 (best 0.696)\n",
            "In epoch 20, loss: 1.592, val acc: 0.700 (best 0.700), test acc: 0.718 (best 0.718)\n",
            "In epoch 25, loss: 1.442, val acc: 0.708 (best 0.708), test acc: 0.724 (best 0.724)\n",
            "In epoch 30, loss: 1.277, val acc: 0.728 (best 0.728), test acc: 0.743 (best 0.743)\n",
            "In epoch 35, loss: 1.103, val acc: 0.742 (best 0.742), test acc: 0.746 (best 0.744)\n",
            "In epoch 40, loss: 0.932, val acc: 0.738 (best 0.742), test acc: 0.754 (best 0.744)\n",
            "In epoch 45, loss: 0.772, val acc: 0.744 (best 0.744), test acc: 0.758 (best 0.757)\n",
            "In epoch 50, loss: 0.629, val acc: 0.752 (best 0.752), test acc: 0.764 (best 0.762)\n",
            "In epoch 55, loss: 0.508, val acc: 0.760 (best 0.760), test acc: 0.760 (best 0.760)\n",
            "In epoch 60, loss: 0.409, val acc: 0.756 (best 0.760), test acc: 0.766 (best 0.760)\n",
            "In epoch 65, loss: 0.329, val acc: 0.760 (best 0.762), test acc: 0.768 (best 0.767)\n",
            "In epoch 70, loss: 0.266, val acc: 0.760 (best 0.762), test acc: 0.767 (best 0.767)\n",
            "In epoch 75, loss: 0.216, val acc: 0.758 (best 0.762), test acc: 0.766 (best 0.767)\n",
            "In epoch 80, loss: 0.178, val acc: 0.756 (best 0.762), test acc: 0.767 (best 0.767)\n",
            "In epoch 85, loss: 0.148, val acc: 0.754 (best 0.762), test acc: 0.771 (best 0.767)\n",
            "In epoch 90, loss: 0.124, val acc: 0.756 (best 0.762), test acc: 0.772 (best 0.767)\n",
            "In epoch 95, loss: 0.106, val acc: 0.756 (best 0.762), test acc: 0.770 (best 0.767)\n",
            "time: 488 ms (started: 2021-03-19 18:59:53 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGyOkpjUlOm_"
      },
      "source": [
        "# How Does DGL Represent A Graph?\n",
        "\n",
        "- Construct a graph in DGL from scratch.\n",
        "\n",
        "- Assign node and edge features to a graph.\n",
        "\n",
        "- Query properties of a DGL graph such as node degrees and connectivity.\n",
        "\n",
        "- Transform a DGL graph into another graph.\n",
        "\n",
        "- Load and save DGL graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgTQHf7dlR1_"
      },
      "source": [
        "## DGL Graph Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkKVY3oxlDeN"
      },
      "source": [
        "import dgl\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "g = dgl.graph(([0, 0, 0, 0, 0], [1, 2, 3, 4, 5]), num_nodes=6)\n",
        "# Equivalently, PyTorch LongTensors also work.\n",
        "g = dgl.graph((torch.LongTensor([0, 0, 0, 0, 0]), torch.LongTensor([1, 2, 3, 4, 5])), num_nodes=6)\n",
        "\n",
        "# You can omit the number of nodes argument if you can tell the number of nodes from the edge list alone.\n",
        "g = dgl.graph(([0, 0, 0, 0, 0], [1, 2, 3, 4, 5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu7j_p6Klcek",
        "outputId": "b29f8a89-c55d-4d9b-8a4e-fc4b75eeb7cc"
      },
      "source": [
        "# Print the source and destination nodes of every edge.\n",
        "print(g.edges())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([0, 0, 0, 0, 0]), tensor([1, 2, 3, 4, 5]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwhFhY60liE-"
      },
      "source": [
        "## Assigning Node and Edge Features to Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQUBJBfJlgGK",
        "outputId": "41678ea3-3753-426c-8726-cebbd6a2e039"
      },
      "source": [
        "# Assign a 3-dimensional node feature vector for each node.\n",
        "g.ndata['x'] = torch.randn(6, 3)\n",
        "# Assign a 4-dimensional edge feature vector for each edge.\n",
        "g.edata['a'] = torch.randn(5, 4)\n",
        "# Assign a 5x4 node feature matrix for each node.  Node and edge features in DGL can be multi-dimensional.\n",
        "g.ndata['y'] = torch.randn(6, 5, 4)\n",
        "\n",
        "print(g.edata['a'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.6067, -0.3907,  1.5339,  0.4664],\n",
            "        [ 1.4048,  0.4527,  0.1840, -0.4003],\n",
            "        [-0.8095,  1.4550, -1.4049,  1.3023],\n",
            "        [-1.2192, -1.8538, -0.5934,  1.0736],\n",
            "        [ 1.1103,  1.1093, -0.6367, -1.8115]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGTOtc_Ylz48"
      },
      "source": [
        "## Querying Graph Structures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmsdshYKlvQt",
        "outputId": "880090fa-9a2a-4c46-cc98-fb3132b71a00"
      },
      "source": [
        "print(g.num_nodes())\n",
        "print(g.num_edges())\n",
        "# Out degrees of the center node\n",
        "print(g.out_degrees(0))\n",
        "# In degrees of the center node - note that the graph is directed so the in degree should be 0.\n",
        "print(g.in_degrees(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "5\n",
            "5\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg2TNa1wl5Kt"
      },
      "source": [
        "## Graph Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpOrWPwgl3Mm"
      },
      "source": [
        "# Induce a subgraph from node 0, node 1 and node 3 from the original graph.\n",
        "sg1 = g.subgraph([0, 1, 3])\n",
        "# Induce a subgraph from edge 0, edge 1 and edge 3 from the original graph.\n",
        "sg2 = g.edge_subgraph([0, 1, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvMBf6nSl746",
        "outputId": "0bb75e5a-4451-4ffa-83af-b387875395a5"
      },
      "source": [
        "# The original IDs of each node in sg1\n",
        "print(sg1.ndata[dgl.NID])\n",
        "# The original IDs of each edge in sg1\n",
        "print(sg1.edata[dgl.EID])\n",
        "# The original IDs of each node in sg2\n",
        "print(sg2.ndata[dgl.NID])\n",
        "# The original IDs of each edge in sg2\n",
        "print(sg2.edata[dgl.EID])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 3])\n",
            "tensor([0, 2])\n",
            "tensor([0, 1, 2, 4])\n",
            "tensor([0, 1, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUnwmjnll9bC",
        "outputId": "9ef7f7c4-de57-47a4-a43f-9bb882da5f39"
      },
      "source": [
        "# The original node feature of each node in sg1\n",
        "print(sg1.ndata['x'])\n",
        "# The original edge feature of each node in sg1\n",
        "print(sg1.edata['a'])\n",
        "# The original node feature of each node in sg2\n",
        "print(sg2.ndata['x'])\n",
        "# The original edge feature of each node in sg2\n",
        "print(sg2.edata['a'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.7200,  1.9185, -1.2768],\n",
            "        [ 0.6329,  1.2710,  0.0509],\n",
            "        [ 1.7366,  0.5627, -0.9224]])\n",
            "tensor([[-1.6067, -0.3907,  1.5339,  0.4664],\n",
            "        [-0.8095,  1.4550, -1.4049,  1.3023]])\n",
            "tensor([[-1.7200,  1.9185, -1.2768],\n",
            "        [ 0.6329,  1.2710,  0.0509],\n",
            "        [-0.4717,  0.8141,  0.0573],\n",
            "        [-0.4007, -0.2372,  1.1367]])\n",
            "tensor([[-1.6067, -0.3907,  1.5339,  0.4664],\n",
            "        [ 1.4048,  0.4527,  0.1840, -0.4003],\n",
            "        [-1.2192, -1.8538, -0.5934,  1.0736]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2nuS5nFl_WJ",
        "outputId": "3e35f6c4-338d-456f-e46e-5fe3cd59a712"
      },
      "source": [
        "newg = dgl.add_reverse_edges(g)\n",
        "newg.edges()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 0, 0, 0, 0, 1, 2, 3, 4, 5]),\n",
              " tensor([1, 2, 3, 4, 5, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bce_pkFmD7W"
      },
      "source": [
        "## Loading and Saving Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obBhP7l-mB2S",
        "outputId": "a30b183b-4a03-4b18-cd54-6beedc1ada29"
      },
      "source": [
        "# Save graphs\n",
        "dgl.save_graphs('graph.dgl', g)\n",
        "dgl.save_graphs('graphs.dgl', [g, sg1, sg2])\n",
        "\n",
        "# Load graphs\n",
        "(g,), _ = dgl.load_graphs('graph.dgl')\n",
        "print(g)\n",
        "(g, sg1, sg2), _ = dgl.load_graphs('graphs.dgl')\n",
        "print(g)\n",
        "print(sg1)\n",
        "print(sg2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graph(num_nodes=6, num_edges=5,\n",
            "      ndata_schemes={'y': Scheme(shape=(5, 4), dtype=torch.float32), 'x': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={'a': Scheme(shape=(4,), dtype=torch.float32)})\n",
            "Graph(num_nodes=6, num_edges=5,\n",
            "      ndata_schemes={'y': Scheme(shape=(5, 4), dtype=torch.float32), 'x': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={'a': Scheme(shape=(4,), dtype=torch.float32)})\n",
            "Graph(num_nodes=3, num_edges=2,\n",
            "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'x': Scheme(shape=(3,), dtype=torch.float32), 'y': Scheme(shape=(5, 4), dtype=torch.float32)}\n",
            "      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'a': Scheme(shape=(4,), dtype=torch.float32)})\n",
            "Graph(num_nodes=4, num_edges=3,\n",
            "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'x': Scheme(shape=(3,), dtype=torch.float32), 'y': Scheme(shape=(5, 4), dtype=torch.float32)}\n",
            "      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), 'a': Scheme(shape=(4,), dtype=torch.float32)})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrhv0wjTmJVR"
      },
      "source": [
        "# Write your own GNN module\n",
        "\n",
        "- Understand DGL’s message passing APIs.\n",
        "\n",
        "- Implement GraphSAGE convolution module by your own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmP1OgC1mF-7"
      },
      "source": [
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETUldI6UmX9i"
      },
      "source": [
        "## Message passing and GNNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yffy8tScmSgW"
      },
      "source": [
        "import dgl.function as fn\n",
        "\n",
        "class SAGEConv(nn.Module):\n",
        "    \"\"\"Graph convolution module used by the GraphSAGE model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_feat : int\n",
        "        Input feature size.\n",
        "    out_feat : int\n",
        "        Output feature size.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv, self).__init__()\n",
        "        # A linear submodule for projecting the input and neighbor feature to the output.\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        \"\"\"Forward computation\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        g : Graph\n",
        "            The input graph.\n",
        "        h : Tensor\n",
        "            The input node feature.\n",
        "        \"\"\"\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            # update_all is a message passing API.\n",
        "            g.update_all(message_func=fn.copy_u('h', 'm'), reduce_func=fn.mean('m', 'h_N'))\n",
        "            h_N = g.ndata['h_N']\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJME8lDcmhvh"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats)\n",
        "        self.conv2 = SAGEConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVjyNrXWmlmt"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siL0OEBpmj8j",
        "outputId": "806e1bbd-ddf4-4fce-d838-2d150e676bbf"
      },
      "source": [
        "import dgl.data\n",
        "\n",
        "dataset = dgl.data.CoraGraphDataset()\n",
        "g = dataset[0]\n",
        "\n",
        "def train(g, model):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    all_logits = []\n",
        "    best_val_acc = 0\n",
        "    best_test_acc = 0\n",
        "\n",
        "    features = g.ndata['feat']\n",
        "    labels = g.ndata['label']\n",
        "    train_mask = g.ndata['train_mask']\n",
        "    val_mask = g.ndata['val_mask']\n",
        "    test_mask = g.ndata['test_mask']\n",
        "    for e in range(200):\n",
        "        # Forward\n",
        "        logits = model(g, features)\n",
        "\n",
        "        # Compute prediction\n",
        "        pred = logits.argmax(1)\n",
        "\n",
        "        # Compute loss\n",
        "        # Note that we should only compute the losses of the nodes in the training set,\n",
        "        # i.e. with train_mask 1.\n",
        "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
        "\n",
        "        # Compute accuracy on training/validation/test\n",
        "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "\n",
        "        # Save the best validation accuracy and the corresponding test accuracy.\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        all_logits.append(logits.detach())\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
        "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))\n",
        "\n",
        "model = Model(g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
        "train(g, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n",
            "In epoch 0, loss: 1.952, val acc: 0.114 (best 0.114), test acc: 0.103 (best 0.103)\n",
            "In epoch 5, loss: 1.873, val acc: 0.400 (best 0.408), test acc: 0.391 (best 0.392)\n",
            "In epoch 10, loss: 1.725, val acc: 0.458 (best 0.458), test acc: 0.500 (best 0.500)\n",
            "In epoch 15, loss: 1.502, val acc: 0.592 (best 0.592), test acc: 0.602 (best 0.602)\n",
            "In epoch 20, loss: 1.211, val acc: 0.660 (best 0.660), test acc: 0.674 (best 0.674)\n",
            "In epoch 25, loss: 0.886, val acc: 0.720 (best 0.720), test acc: 0.727 (best 0.727)\n",
            "In epoch 30, loss: 0.581, val acc: 0.756 (best 0.756), test acc: 0.749 (best 0.749)\n",
            "In epoch 35, loss: 0.349, val acc: 0.770 (best 0.770), test acc: 0.771 (best 0.771)\n",
            "In epoch 40, loss: 0.200, val acc: 0.768 (best 0.770), test acc: 0.776 (best 0.771)\n",
            "In epoch 45, loss: 0.116, val acc: 0.758 (best 0.770), test acc: 0.774 (best 0.771)\n",
            "In epoch 50, loss: 0.070, val acc: 0.756 (best 0.770), test acc: 0.773 (best 0.771)\n",
            "In epoch 55, loss: 0.045, val acc: 0.754 (best 0.770), test acc: 0.771 (best 0.771)\n",
            "In epoch 60, loss: 0.031, val acc: 0.750 (best 0.770), test acc: 0.769 (best 0.771)\n",
            "In epoch 65, loss: 0.023, val acc: 0.748 (best 0.770), test acc: 0.771 (best 0.771)\n",
            "In epoch 70, loss: 0.018, val acc: 0.754 (best 0.770), test acc: 0.772 (best 0.771)\n",
            "In epoch 75, loss: 0.015, val acc: 0.754 (best 0.770), test acc: 0.769 (best 0.771)\n",
            "In epoch 80, loss: 0.013, val acc: 0.756 (best 0.770), test acc: 0.767 (best 0.771)\n",
            "In epoch 85, loss: 0.011, val acc: 0.756 (best 0.770), test acc: 0.767 (best 0.771)\n",
            "In epoch 90, loss: 0.010, val acc: 0.756 (best 0.770), test acc: 0.768 (best 0.771)\n",
            "In epoch 95, loss: 0.009, val acc: 0.758 (best 0.770), test acc: 0.769 (best 0.771)\n",
            "In epoch 100, loss: 0.008, val acc: 0.758 (best 0.770), test acc: 0.766 (best 0.771)\n",
            "In epoch 105, loss: 0.007, val acc: 0.762 (best 0.770), test acc: 0.764 (best 0.771)\n",
            "In epoch 110, loss: 0.007, val acc: 0.764 (best 0.770), test acc: 0.763 (best 0.771)\n",
            "In epoch 115, loss: 0.006, val acc: 0.764 (best 0.770), test acc: 0.765 (best 0.771)\n",
            "In epoch 120, loss: 0.006, val acc: 0.764 (best 0.770), test acc: 0.764 (best 0.771)\n",
            "In epoch 125, loss: 0.006, val acc: 0.764 (best 0.770), test acc: 0.764 (best 0.771)\n",
            "In epoch 130, loss: 0.005, val acc: 0.764 (best 0.770), test acc: 0.763 (best 0.771)\n",
            "In epoch 135, loss: 0.005, val acc: 0.764 (best 0.770), test acc: 0.762 (best 0.771)\n",
            "In epoch 140, loss: 0.005, val acc: 0.764 (best 0.770), test acc: 0.762 (best 0.771)\n",
            "In epoch 145, loss: 0.004, val acc: 0.764 (best 0.770), test acc: 0.761 (best 0.771)\n",
            "In epoch 150, loss: 0.004, val acc: 0.764 (best 0.770), test acc: 0.761 (best 0.771)\n",
            "In epoch 155, loss: 0.004, val acc: 0.766 (best 0.770), test acc: 0.760 (best 0.771)\n",
            "In epoch 160, loss: 0.004, val acc: 0.766 (best 0.770), test acc: 0.760 (best 0.771)\n",
            "In epoch 165, loss: 0.004, val acc: 0.766 (best 0.770), test acc: 0.760 (best 0.771)\n",
            "In epoch 170, loss: 0.003, val acc: 0.766 (best 0.770), test acc: 0.760 (best 0.771)\n",
            "In epoch 175, loss: 0.003, val acc: 0.766 (best 0.770), test acc: 0.760 (best 0.771)\n",
            "In epoch 180, loss: 0.003, val acc: 0.766 (best 0.770), test acc: 0.759 (best 0.771)\n",
            "In epoch 185, loss: 0.003, val acc: 0.766 (best 0.770), test acc: 0.760 (best 0.771)\n",
            "In epoch 190, loss: 0.003, val acc: 0.766 (best 0.770), test acc: 0.760 (best 0.771)\n",
            "In epoch 195, loss: 0.003, val acc: 0.764 (best 0.770), test acc: 0.760 (best 0.771)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HwSJZl-mwS2"
      },
      "source": [
        "## More customization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzOz3DSvmnzU"
      },
      "source": [
        "class WeightedSAGEConv(nn.Module):\n",
        "    \"\"\"Graph convolution module used by the GraphSAGE model with edge weights.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_feat : int\n",
        "        Input feature size.\n",
        "    out_feat : int\n",
        "        Output feature size.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(WeightedSAGEConv, self).__init__()\n",
        "        # A linear submodule for projecting the input and neighbor feature to the output.\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h, w):\n",
        "        \"\"\"Forward computation\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        g : Graph\n",
        "            The input graph.\n",
        "        h : Tensor\n",
        "            The input node feature.\n",
        "        w : Tensor\n",
        "            The edge weight.\n",
        "        \"\"\"\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            g.edata['w'] = w\n",
        "            g.update_all(message_func=fn.u_mul_e('h', 'w', 'm'), reduce_func=fn.mean('m', 'h_N'))\n",
        "            h_N = g.ndata['h_N']\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmCXyO7Bm81v",
        "outputId": "6951f4e2-cb23-4aeb-b208-15a36c3dbbb9"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = WeightedSAGEConv(in_feats, h_feats)\n",
        "        self.conv2 = WeightedSAGEConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat, torch.ones(g.num_edges()).to(g.device))\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h, torch.ones(g.num_edges()).to(g.device))\n",
        "        return h\n",
        "\n",
        "model = Model(g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
        "train(g, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In epoch 0, loss: 1.949, val acc: 0.122 (best 0.122), test acc: 0.130 (best 0.130)\n",
            "In epoch 5, loss: 1.863, val acc: 0.458 (best 0.458), test acc: 0.456 (best 0.456)\n",
            "In epoch 10, loss: 1.713, val acc: 0.230 (best 0.458), test acc: 0.230 (best 0.456)\n",
            "In epoch 15, loss: 1.494, val acc: 0.292 (best 0.458), test acc: 0.280 (best 0.456)\n",
            "In epoch 20, loss: 1.218, val acc: 0.380 (best 0.458), test acc: 0.381 (best 0.456)\n",
            "In epoch 25, loss: 0.910, val acc: 0.532 (best 0.532), test acc: 0.507 (best 0.507)\n",
            "In epoch 30, loss: 0.616, val acc: 0.626 (best 0.626), test acc: 0.605 (best 0.605)\n",
            "In epoch 35, loss: 0.382, val acc: 0.710 (best 0.710), test acc: 0.680 (best 0.680)\n",
            "In epoch 40, loss: 0.224, val acc: 0.728 (best 0.728), test acc: 0.722 (best 0.722)\n",
            "In epoch 45, loss: 0.130, val acc: 0.730 (best 0.730), test acc: 0.731 (best 0.723)\n",
            "In epoch 50, loss: 0.078, val acc: 0.728 (best 0.732), test acc: 0.738 (best 0.736)\n",
            "In epoch 55, loss: 0.049, val acc: 0.732 (best 0.732), test acc: 0.739 (best 0.736)\n",
            "In epoch 60, loss: 0.033, val acc: 0.734 (best 0.734), test acc: 0.737 (best 0.739)\n",
            "In epoch 65, loss: 0.024, val acc: 0.734 (best 0.736), test acc: 0.741 (best 0.737)\n",
            "In epoch 70, loss: 0.019, val acc: 0.738 (best 0.738), test acc: 0.741 (best 0.741)\n",
            "In epoch 75, loss: 0.015, val acc: 0.738 (best 0.740), test acc: 0.744 (best 0.743)\n",
            "In epoch 80, loss: 0.013, val acc: 0.738 (best 0.740), test acc: 0.740 (best 0.743)\n",
            "In epoch 85, loss: 0.011, val acc: 0.738 (best 0.740), test acc: 0.742 (best 0.743)\n",
            "In epoch 90, loss: 0.010, val acc: 0.738 (best 0.740), test acc: 0.739 (best 0.743)\n",
            "In epoch 95, loss: 0.009, val acc: 0.738 (best 0.740), test acc: 0.740 (best 0.743)\n",
            "In epoch 100, loss: 0.008, val acc: 0.742 (best 0.742), test acc: 0.740 (best 0.740)\n",
            "In epoch 105, loss: 0.008, val acc: 0.742 (best 0.742), test acc: 0.740 (best 0.740)\n",
            "In epoch 110, loss: 0.007, val acc: 0.742 (best 0.742), test acc: 0.740 (best 0.740)\n",
            "In epoch 115, loss: 0.006, val acc: 0.740 (best 0.742), test acc: 0.740 (best 0.740)\n",
            "In epoch 120, loss: 0.006, val acc: 0.740 (best 0.742), test acc: 0.740 (best 0.740)\n",
            "In epoch 125, loss: 0.006, val acc: 0.740 (best 0.742), test acc: 0.740 (best 0.740)\n",
            "In epoch 130, loss: 0.005, val acc: 0.738 (best 0.742), test acc: 0.740 (best 0.740)\n",
            "In epoch 135, loss: 0.005, val acc: 0.738 (best 0.742), test acc: 0.740 (best 0.740)\n",
            "In epoch 140, loss: 0.005, val acc: 0.738 (best 0.742), test acc: 0.740 (best 0.740)\n",
            "In epoch 145, loss: 0.004, val acc: 0.738 (best 0.742), test acc: 0.740 (best 0.740)\n",
            "In epoch 150, loss: 0.004, val acc: 0.738 (best 0.742), test acc: 0.739 (best 0.740)\n",
            "In epoch 155, loss: 0.004, val acc: 0.736 (best 0.742), test acc: 0.739 (best 0.740)\n",
            "In epoch 160, loss: 0.004, val acc: 0.738 (best 0.742), test acc: 0.739 (best 0.740)\n",
            "In epoch 165, loss: 0.004, val acc: 0.738 (best 0.742), test acc: 0.739 (best 0.740)\n",
            "In epoch 170, loss: 0.003, val acc: 0.738 (best 0.742), test acc: 0.739 (best 0.740)\n",
            "In epoch 175, loss: 0.003, val acc: 0.738 (best 0.742), test acc: 0.739 (best 0.740)\n",
            "In epoch 180, loss: 0.003, val acc: 0.736 (best 0.742), test acc: 0.738 (best 0.740)\n",
            "In epoch 185, loss: 0.003, val acc: 0.736 (best 0.742), test acc: 0.738 (best 0.740)\n",
            "In epoch 190, loss: 0.003, val acc: 0.736 (best 0.742), test acc: 0.738 (best 0.740)\n",
            "In epoch 195, loss: 0.003, val acc: 0.736 (best 0.742), test acc: 0.738 (best 0.740)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myKmBWFmnCP8"
      },
      "source": [
        "## Even more customization by user-defined function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlEF30mqm-j6"
      },
      "source": [
        "def u_mul_e_udf(edges):\n",
        "    return {'m' : edges.src['h'] * edges.data['w']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac7bilUcnEw0"
      },
      "source": [
        "def sum_udf(nodes):\n",
        "    return {'h': nodes.mailbox['m'].sum(1)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHBy-PSenLla"
      },
      "source": [
        "## Best practice of writing custom GNN modules\n",
        "DGL recommends the following practice ranked by preference:\n",
        "\n",
        "- Use dgl.nn modules.\n",
        "\n",
        "- Use dgl.nn.functional functions which contain lower-level complex operations such as computing a softmax for each node over incoming edges.\n",
        "\n",
        "- Use update_all with builtin message and reduce functions.\n",
        "\n",
        "- Use user-defined message or reduce functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVmOVTe4nXdw"
      },
      "source": [
        "# Link Prediction using Graph Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPNY-ScwnGWQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "079b23d2-7141-4b30-9d46-eafc9dc86906"
      },
      "source": [
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "import numpy as np\n",
        "import scipy.sparse as sp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.55 ms (started: 2021-03-19 19:13:30 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev5hpKckngmc"
      },
      "source": [
        "## Overview of Link Prediction with GNN\n",
        "This tutorial formulates the link prediction problem as a binary classification problem as follows:\n",
        "\n",
        "- Treat the edges in the graph as positive examples.\n",
        "\n",
        "- Sample a number of non-existent edges (i.e. node pairs with no edges between them) as negative examples.\n",
        "\n",
        "- Divide the positive examples and negative examples into a training set and a test set.\n",
        "\n",
        "- Evaluate the model with any binary classification metric such as Area Under Curve (AUC)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6rDt1IPnonY"
      },
      "source": [
        "## Loading graph and features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qzpvh1zncPz",
        "outputId": "4ad88cd9-9056-4d38-89a4-50c4b6f21312"
      },
      "source": [
        "import dgl.data\n",
        "\n",
        "dataset = dgl.data.CoraGraphDataset()\n",
        "g = dataset[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n",
            "time: 114 ms (started: 2021-03-19 19:13:34 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h2jXcfynsv4"
      },
      "source": [
        "## Prepare training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvxfwfHsnqRs"
      },
      "source": [
        "# Split edge set for training and testing\n",
        "u, v = g.edges()\n",
        "\n",
        "eids = np.arange(g.number_of_edges())\n",
        "eids = np.random.permutation(eids)\n",
        "test_size = int(len(eids) * 0.1)\n",
        "train_size = g.number_of_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "\n",
        "# Find all negative edges and split them for training and testing\n",
        "# print(\"np.ones(len(u)) = \", np.ones(len(u)))\n",
        "# print(\"u.numpy() = \", u.numpy())\n",
        "# print(\"v.numpy() = \", v.numpy())\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
        "# print(\"adj = \", adj)\n",
        "# print(\"adj.todense() = \", adj.todense())\n",
        "# print(\"np.eye(g.number_of_nodes()) = \", np.eye(g.number_of_nodes()))\n",
        "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
        "# print(\"adj_neg = \", adj_neg)\n",
        "neg_u, neg_v = np.where(adj_neg != 0)\n",
        "\n",
        "neg_eids = np.random.choice(len(neg_u), g.number_of_edges() // 2)\n",
        "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
        "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5RoxKSdnvUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e456ea-e2c0-4c5b-edce-eb25d6f08017"
      },
      "source": [
        "train_g = dgl.remove_edges(g, eids[:test_size])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 9.63 ms (started: 2021-03-19 19:42:31 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTjrt2Pxny44"
      },
      "source": [
        "## Define a GraphSAGE model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_L5QwFhnxGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d811b66f-0ad0-4dfe-e3c8-5f69e8509f6a"
      },
      "source": [
        "from dgl.nn import SAGEConv\n",
        "\n",
        "# ----------- 2. create model -------------- #\n",
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 6.44 ms (started: 2021-03-19 19:43:38 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORmxfgK2oClF"
      },
      "source": [
        "## Positive graph, negative graph, and `apply_edges`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eim6yVhJn1Kq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb930039-bdf9-4d0f-aed4-e70f549cee12"
      },
      "source": [
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
        "\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 9.52 ms (started: 2021-03-19 20:09:09 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vava9N3oj_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f618def9-3432-4220-9e62-7e6f5f445b54"
      },
      "source": [
        "import dgl.function as fn\n",
        "\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            # Compute a new edge feature named 'score' by a dot-product between the\n",
        "            # source node feature 'h' and destination node feature 'h'.\n",
        "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
        "            return g.edata['score'][:, 0]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.98 ms (started: 2021-03-19 20:09:11 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj_b1xXbol7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04643057-209b-48ef-eb1f-9ab6c843befb"
      },
      "source": [
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self, h_feats):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
        "        self.W2 = nn.Linear(h_feats, 1)\n",
        "\n",
        "    def apply_edges(self, edges):\n",
        "        \"\"\"\n",
        "        Computes a scalar score for each edge of the given graph.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        edges :\n",
        "            Has three members ``src``, ``dst`` and ``data``, each of\n",
        "            which is a dictionary representing the features of the\n",
        "            source nodes, the destination nodes, and the edges\n",
        "            themselves.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dict\n",
        "            A dictionary of new edge features.\n",
        "        \"\"\"\n",
        "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
        "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            g.apply_edges(self.apply_edges)\n",
        "            return g.edata['score']"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 9.52 ms (started: 2021-03-19 20:09:13 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KdOJMsoowq6"
      },
      "source": [
        "## Training loop\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFy6e6i0oplF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711ded8c-7ef9-47f0-f0a3-818865d1456d"
      },
      "source": [
        "model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)\n",
        "# You can replace DotPredictor with MLPPredictor.\n",
        "#pred = MLPPredictor(16)\n",
        "pred = DotPredictor()\n",
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "    return roc_auc_score(labels, scores)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 18.5 ms (started: 2021-03-19 20:09:17 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRKOTVpIpAV_",
        "outputId": "b4cdd45e-0d33-45f7-e882-d445b436a173"
      },
      "source": [
        "# ----------- 3. set up loss and optimizer -------------- #\n",
        "# in this case, loss will in training loop\n",
        "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "all_logits = []\n",
        "for e in range(100):\n",
        "    # forward\n",
        "    h = model(train_g, train_g.ndata['feat'])\n",
        "    pos_score = pred(train_pos_g, h)\n",
        "    neg_score = pred(train_neg_g, h)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print('In epoch {}, loss: {}'.format(e, loss))\n",
        "\n",
        "# ----------- 5. check results ------------------------ #\n",
        "from sklearn.metrics import roc_auc_score\n",
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "    print('AUC', compute_auc(pos_score, neg_score))\n",
        "\n",
        "\n",
        "# Thumbnail Courtesy: Link Prediction with Neo4j, Mark Needham\n",
        "# sphinx_gallery_thumbnail_path = '_static/blitz_4_link_predict.png'"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In epoch 0, loss: 0.6177338361740112\n",
            "In epoch 5, loss: 0.6021549701690674\n",
            "In epoch 10, loss: 0.5715932250022888\n",
            "In epoch 15, loss: 0.5184945464134216\n",
            "In epoch 20, loss: 0.44610998034477234\n",
            "In epoch 25, loss: 0.3957952857017517\n",
            "In epoch 30, loss: 0.34818312525749207\n",
            "In epoch 35, loss: 0.3054206073284149\n",
            "In epoch 40, loss: 0.2675386667251587\n",
            "In epoch 45, loss: 0.23587919771671295\n",
            "In epoch 50, loss: 0.20788024365901947\n",
            "In epoch 55, loss: 0.18020963668823242\n",
            "In epoch 60, loss: 0.15578201413154602\n",
            "In epoch 65, loss: 0.1317504197359085\n",
            "In epoch 70, loss: 0.110292449593544\n",
            "In epoch 75, loss: 0.09030572324991226\n",
            "In epoch 80, loss: 0.07257099449634552\n",
            "In epoch 85, loss: 0.05705918371677399\n",
            "In epoch 90, loss: 0.04370430111885071\n",
            "In epoch 95, loss: 0.032618604600429535\n",
            "AUC 0.8632950742346308\n",
            "time: 4.39 s (started: 2021-03-19 20:09:19 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5lAv1zBpFZj"
      },
      "source": [
        "# Training a GNN for Graph Classification\n",
        "Train a graph classification model for a small dataset from the paper [How Powerful Are Graph Neural Networks](https://arxiv.org/abs/1810.00826).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8D3Z04RpBv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0bdfe0-3a3d-428b-ba6e-7ce21946e3fa"
      },
      "source": [
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.46 ms (started: 2021-03-19 20:10:12 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFHdG9ygpKWz"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0io00pTpHOq",
        "outputId": "83ce498c-cc5a-47b1-f452-e4c819fc381c"
      },
      "source": [
        "import dgl.data\n",
        "\n",
        "# Generate a synthetic dataset with 10000 graphs, ranging from 10 to 500 nodes.\n",
        "dataset = dgl.data.GINDataset('PROTEINS', self_loop=True)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.dgl/GINDataset.zip from https://raw.githubusercontent.com/weihua916/powerful-gnns/master/dataset.zip...\n",
            "Extracting file to /root/.dgl/GINDataset\n",
            "time: 23 s (started: 2021-03-19 20:10:17 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzvC6vpcpYF7",
        "outputId": "b5a01931-85db-450e-fb87-19e4052ce5eb"
      },
      "source": [
        "print('Node feature dimensionality:', dataset.dim_nfeats)\n",
        "print('Number of graph categories:', dataset.gclasses)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Node feature dimensionality: 3\n",
            "Number of graph categories: 2\n",
            "time: 1.56 ms (started: 2021-03-19 20:10:40 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P1wiTFApa8B"
      },
      "source": [
        "## Defining Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fdefSBupYwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c31ccca-c387-4001-c247-bc541fdf9fac"
      },
      "source": [
        "from dgl.dataloading import GraphDataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "num_examples = len(dataset)\n",
        "num_train = int(num_examples * 0.8)\n",
        "\n",
        "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
        "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_examples))\n",
        "\n",
        "train_dataloader = GraphDataLoader(\n",
        "    dataset, sampler=train_sampler, batch_size=5, drop_last=False)\n",
        "test_dataloader = GraphDataLoader(\n",
        "    dataset, sampler=test_sampler, batch_size=5, drop_last=False)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 5.02 ms (started: 2021-03-19 20:12:41 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgj58mdhpcuT",
        "outputId": "10403523-0a05-4394-d5aa-2d17787bb741"
      },
      "source": [
        "it = iter(train_dataloader)\n",
        "batch = next(it)\n",
        "print(batch)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Graph(num_nodes=288, num_edges=1294,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'attr': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={}), tensor([0, 0, 0, 0, 0])]\n",
            "time: 9.23 ms (started: 2021-03-19 20:12:44 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjq7u620pf-z"
      },
      "source": [
        "## A Batched Graph in DGL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXdCIIGspeCs",
        "outputId": "a03a8d06-5543-48bd-b9fe-8c59e3e20be4"
      },
      "source": [
        "batched_graph, labels = batch\n",
        "print('Number of nodes for each graph element in the batch:', batched_graph.batch_num_nodes())\n",
        "print('Number of edges for each graph element in the batch:', batched_graph.batch_num_edges())\n",
        "\n",
        "# Recover the original graph elements from the minibatch\n",
        "graphs = dgl.unbatch(batched_graph)\n",
        "print('The original graphs in the minibatch:')\n",
        "print(graphs)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of nodes for each graph element in the batch: tensor([38, 85, 48, 28, 89])\n",
            "Number of edges for each graph element in the batch: tensor([198, 401, 196, 124, 375])\n",
            "The original graphs in the minibatch:\n",
            "[Graph(num_nodes=38, num_edges=198,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'attr': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={}), Graph(num_nodes=85, num_edges=401,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'attr': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={}), Graph(num_nodes=48, num_edges=196,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'attr': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={}), Graph(num_nodes=28, num_edges=124,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'attr': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={}), Graph(num_nodes=89, num_edges=375,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'attr': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={})]\n",
            "time: 10.8 ms (started: 2021-03-19 20:12:46 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUnfaNyTpj3W"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXPnNQ2vphrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b36daa21-6f59-4197-fdf4-e0d801c23215"
      },
      "source": [
        "from dgl.nn import GraphConv\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        g.ndata['h'] = h\n",
        "        return dgl.mean_nodes(g, 'h')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 8.86 ms (started: 2021-03-19 20:12:52 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgveRAASpsT4"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdvpnp4Mplqp",
        "outputId": "4b976dcb-5cbb-4b94-bbba-4574a266e48e"
      },
      "source": [
        "# Create the model with given dimensions\n",
        "model = GCN(dataset.dim_nfeats, 16, dataset.gclasses)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(20):\n",
        "    for batched_graph, labels in train_dataloader:\n",
        "        pred = model(batched_graph, batched_graph.ndata['attr'].float())\n",
        "        loss = F.cross_entropy(pred, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "num_correct = 0\n",
        "num_tests = 0\n",
        "for batched_graph, labels in test_dataloader:\n",
        "    pred = model(batched_graph, batched_graph.ndata['attr'].float())\n",
        "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
        "    num_tests += len(labels)\n",
        "\n",
        "print('Test accuracy:', num_correct / num_tests)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.21524663677130046\n",
            "time: 9.85 s (started: 2021-03-19 20:12:59 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKD5Q_PKp14C"
      },
      "source": [
        "# Make Your Own Dataset\n",
        "Create your own graph dataset for node classification, link prediction, or graph classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiQHNLd9p7W-"
      },
      "source": [
        "## `DGLDataset` Object Overview\n",
        "\n",
        "Your custom graph dataset should inherit the dgl.data.DGLDataset class and implement the following methods:\n",
        "\n",
        "`__getitem__(self, i)`: retrieve the i-th example of the dataset. An example often contains a single DGL graph, and occasionally its label.\n",
        "\n",
        "`__len__(self)`: the number of examples in the dataset.\n",
        "\n",
        "`process(self)`: load and process raw data from disk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZfa5-ONqFXR"
      },
      "source": [
        "## Creating a Dataset for Node Classification or Link Prediction from CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "czb3S2D7puqo",
        "outputId": "6c35fce7-c658-420a-c800-eda862ecb557"
      },
      "source": [
        "import urllib.request\n",
        "import pandas as pd\n",
        "urllib.request.urlretrieve(\n",
        "    'https://data.dgl.ai/tutorial/dataset/members.csv', './members.csv')\n",
        "urllib.request.urlretrieve(\n",
        "    'https://data.dgl.ai/tutorial/dataset/interactions.csv', './interactions.csv')\n",
        "\n",
        "members = pd.read_csv('./members.csv')\n",
        "members.head()\n",
        "\n",
        "interactions = pd.read_csv('./interactions.csv')\n",
        "interactions.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Src</th>\n",
              "      <th>Dst</th>\n",
              "      <th>Weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.043591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.282119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.370293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.730570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.821187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Src  Dst    Weight\n",
              "0    0    1  0.043591\n",
              "1    0    2  0.282119\n",
              "2    0    3  0.370293\n",
              "3    0    4  0.730570\n",
              "4    0    5  0.821187"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxjOC3_RqHeq",
        "outputId": "499a1379-1eec-44f9-be3c-fa9d9b9b0727"
      },
      "source": [
        "import dgl\n",
        "from dgl.data import DGLDataset\n",
        "import torch\n",
        "import os\n",
        "\n",
        "class KarateClubDataset(DGLDataset):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='karate_club')\n",
        "\n",
        "    def process(self):\n",
        "        nodes_data = pd.read_csv('./members.csv')\n",
        "        edges_data = pd.read_csv('./interactions.csv')\n",
        "        node_features = torch.from_numpy(nodes_data['Age'].to_numpy())\n",
        "        node_labels = torch.from_numpy(nodes_data['Club'].astype('category').cat.codes.to_numpy())\n",
        "        edge_features = torch.from_numpy(edges_data['Weight'].to_numpy())\n",
        "        edges_src = torch.from_numpy(edges_data['Src'].to_numpy())\n",
        "        edges_dst = torch.from_numpy(edges_data['Dst'].to_numpy())\n",
        "\n",
        "        self.graph = dgl.graph((edges_src, edges_dst), num_nodes=nodes_data.shape[0])\n",
        "        self.graph.ndata['feat'] = node_features\n",
        "        self.graph.ndata['label'] = node_labels\n",
        "        self.graph.edata['weight'] = edge_features\n",
        "\n",
        "        # If your dataset is a node classification dataset, you will need to assign\n",
        "        # masks indicating whether a node belongs to training, validation, and test set.\n",
        "        n_nodes = nodes_data.shape[0]\n",
        "        n_train = int(n_nodes * 0.6)\n",
        "        n_val = int(n_nodes * 0.2)\n",
        "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        train_mask[:n_train] = True\n",
        "        val_mask[n_train:n_train + n_val] = True\n",
        "        test_mask[n_train + n_val:] = True\n",
        "        self.graph.ndata['train_mask'] = train_mask\n",
        "        self.graph.ndata['val_mask'] = val_mask\n",
        "        self.graph.ndata['test_mask'] = test_mask\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.graph\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "dataset = KarateClubDataset()\n",
        "graph = dataset[0]\n",
        "\n",
        "print(graph)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graph(num_nodes=34, num_edges=156,\n",
            "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int8), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
            "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF9fVASzqLrW"
      },
      "source": [
        "## Creating a Dataset for Graph Classification from CSV\n",
        "This tutorial demonstrates how to create a graph classification dataset with the following synthetic CSV data:\n",
        "\n",
        "- `graph_edges.csv`: containing three columns:\n",
        "\n",
        "  - `graph_id`: the ID of the graph.\n",
        "\n",
        "  - `src`: the source node of an edge of the given graph.\n",
        "\n",
        "  - `dst`: the destination node of an edge of the given graph.\n",
        "\n",
        "- `graph_properties.csv`: containing three columns:\n",
        "\n",
        "  - `graph_id`: the ID of the graph.\n",
        "\n",
        "  - `label`: the label of the graph.\n",
        "\n",
        "  - `num_nodes`: the number of nodes in the graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLAlrRM7qJQ3",
        "outputId": "78b2a5b5-a7a7-4c42-a3a7-92f4300221ba"
      },
      "source": [
        "urllib.request.urlretrieve(\n",
        "    'https://data.dgl.ai/tutorial/dataset/graph_edges.csv', './graph_edges.csv')\n",
        "urllib.request.urlretrieve(\n",
        "    'https://data.dgl.ai/tutorial/dataset/graph_properties.csv', './graph_properties.csv')\n",
        "edges = pd.read_csv('./graph_edges.csv')\n",
        "properties = pd.read_csv('./graph_properties.csv')\n",
        "\n",
        "edges.head()\n",
        "\n",
        "properties.head()\n",
        "\n",
        "class SyntheticDataset(DGLDataset):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='synthetic')\n",
        "\n",
        "    def process(self):\n",
        "        edges = pd.read_csv('./graph_edges.csv')\n",
        "        properties = pd.read_csv('./graph_properties.csv')\n",
        "        self.graphs = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Create a graph for each graph ID from the edges table.\n",
        "        # First process the properties table into two dictionaries with graph IDs as keys.\n",
        "        # The label and number of nodes are values.\n",
        "        label_dict = {}\n",
        "        num_nodes_dict = {}\n",
        "        for _, row in properties.iterrows():\n",
        "            label_dict[row['graph_id']] = row['label']\n",
        "            num_nodes_dict[row['graph_id']] = row['num_nodes']\n",
        "\n",
        "        # For the edges, first group the table by graph IDs.\n",
        "        edges_group = edges.groupby('graph_id')\n",
        "\n",
        "        # For each graph ID...\n",
        "        for graph_id in edges_group.groups:\n",
        "            # Find the edges as well as the number of nodes and its label.\n",
        "            edges_of_id = edges_group.get_group(graph_id)\n",
        "            src = edges_of_id['src'].to_numpy()\n",
        "            dst = edges_of_id['dst'].to_numpy()\n",
        "            num_nodes = num_nodes_dict[graph_id]\n",
        "            label = label_dict[graph_id]\n",
        "\n",
        "            # Create a graph and add it to the list of graphs and labels.\n",
        "            g = dgl.graph((src, dst), num_nodes=num_nodes)\n",
        "            self.graphs.append(g)\n",
        "            self.labels.append(label)\n",
        "\n",
        "        # Convert the label list to tensor for saving.\n",
        "        self.labels = torch.LongTensor(self.labels)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.graphs[i], self.labels[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "\n",
        "dataset = SyntheticDataset()\n",
        "graph, label = dataset[0]\n",
        "print(graph, label)\n",
        "\n",
        "\n",
        "# Thumbnail Courtesy: (Un)common Use Cases for Graph Databases, Michal Bachman\n",
        "# sphinx_gallery_thumbnail_path = '_static/blitz_6_load_data.png'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graph(num_nodes=15, num_edges=45,\n",
            "      ndata_schemes={}\n",
            "      edata_schemes={}) tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLyYsbIDqfAJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}